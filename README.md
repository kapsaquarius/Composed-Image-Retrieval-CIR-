**Composed-Image-Retrieval**

A CIR model developed using the CLIP vision-language model to retrieve target images of clothing based on a reference image and text modifier. Implemented on a specialized clothing dataset, enhancing the model's ability to generate styled images by integrating visual and textual inputs effectively. 
